{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sample(sample, train_size, permute):\n",
    "    sample_copy = sample.copy()\n",
    "    size = int(train_size * len(sample_copy))\n",
    "    \n",
    "    if permute == True:\n",
    "        np.random.seed(2)\n",
    "        shuffled_indeces = np.arange(len(sample))\n",
    "        np.random.shuffle(shuffled_indeces)\n",
    "        indeces_train = shuffled_indeces[:size]\n",
    "        indeces_test = shuffled_indeces[size:]\n",
    "\n",
    "    elif permute == False:\n",
    "        indeces_train = np.arange(len(sample))[:size]\n",
    "        indeces_test = np.arange(len(sample))[size:]\n",
    "\n",
    "    train_sample = sample_copy.iloc[indeces_train]\n",
    "    test_sample = sample_copy.iloc[indeces_test]\n",
    "    return train_sample, test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigens_and_conidtion(X, printing='yes'):\n",
    "    covXX = X.T.dot(X)\n",
    "    if printing == 'yes':\n",
    "        eigs_covXX = np.linalg.eig(covXX)[0]\n",
    "        cond_num_covXX = max(abs(eigs_covXX)) / min(abs(eigs_covXX))\n",
    "    \n",
    "        print('eigenvalues: {}'.format(eigs_covXX))\n",
    "        print('condition number: {}'.format(cond_num_covXX))\n",
    "    return covXX\n",
    "\n",
    "def model_coeffs(X_train, Y_train, covXX):\n",
    "    return np.linalg.pinv(covXX).dot(X_train.T).dot(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_y_splitting(data, regressors_ind, explained_var_ind):\n",
    "    df = pd.DataFrame(data[regressors_ind])\n",
    "    n = df.shape[0]\n",
    "    X = df.copy()\n",
    "    Y = pd.DataFrame(data[explained_var_ind])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_normalize(df, mu=None, sigma=None):\n",
    "    df_normalized = df.copy()\n",
    "    if mu is None and sigma is None:\n",
    "        mu = df_normalized.mean()\n",
    "        sigma = df_normalized.std(ddof=1)\n",
    "    df_normalized = (df_normalized - mu) / sigma\n",
    "    return df_normalized, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_filtering(train_sample, predictors, explained_var):\n",
    "    lst = []\n",
    "    \n",
    "    for predictor in predictors:\n",
    "        predictor_mean = train_sample[predictor].mean()\n",
    "        explained_var_mean = train_sample[explained_var].mean()\n",
    "        \n",
    "        predictor_demeaned = train_sample[predictor] - predictor_mean\n",
    "        explained_demeaned = train_sample[explained_var] - explained_var_mean\n",
    "        \n",
    "        cov_predictor_explained = np.sum(predictor_demeaned * explained_demeaned)\n",
    "        predictor_variance = np.sum(np.square(predictor_demeaned))\n",
    "        explained_variance = np.sum(np.square(explained_demeaned))\n",
    "        \n",
    "        R = cov_predictor_explained / (np.sqrt(predictor_variance * explained_variance))\n",
    "        #lst.append((predictor, R))\n",
    "        lst.append(R)\n",
    "    corr_df = pd.DataFrame(data=lst, index=predictors, columns=[explained_var])\n",
    "    display(corr_df)\n",
    "    \n",
    "    return corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_corr(train_sample, predictors):\n",
    "    corr_matr = np.zeros((len(predictors), len(predictors)))\n",
    "    for predictor_first in predictors:\n",
    "        for predictor_second in predictors:\n",
    "            predictor_first_mean = train_sample[predictor_first].mean()\n",
    "            predictor_second_mean = train_sample[predictor_second].mean()\n",
    "        \n",
    "            predictor_first_demeaned = train_sample[predictor_first] - predictor_first_mean\n",
    "            predictor_second_demeaned = train_sample[predictor_second] - predictor_second_mean\n",
    "        \n",
    "            cov_predictor_first_predictor_second = np.sum(predictor_first_demeaned * predictor_second_demeaned)\n",
    "            predictor_first_variance = np.sum(np.square(predictor_first_demeaned))\n",
    "            epredictor_second_variance = np.sum(np.square(predictor_second_demeaned))\n",
    "        \n",
    "            R = cov_predictor_first_predictor_second / (np.sqrt(predictor_first_variance * epredictor_second_variance))\n",
    "            i = int(np.where(np.array(predictors) == predictor_first)[0])\n",
    "            j = int(np.where(np.array(predictors) == predictor_second)[0])\n",
    "            corr_matr[i][j] = R\n",
    "    corr_data = pd.DataFrame(data=corr_matr, index=predictors, columns=predictors)\n",
    "    display(corr_data)\n",
    "    \n",
    "    return corr_data     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_ones(X, name=\"Ones\"):\n",
    "    X_copy = X.copy()\n",
    "    n = X.shape[0]\n",
    "    X_copy.insert(0, name, np.ones((n, 1)), True)\n",
    "    return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_l2(Y_hat, Y):\n",
    "    Y_hat_arr, Y_arr = np.array(Y_hat), np.array(Y)\n",
    "    return (np.square((Y_hat_arr - Y_arr))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_huber(Y_hat, Y, delta=1.35):\n",
    "    Y_hat_arr, Y_arr = np.array(Y_hat), np.array(Y)\n",
    "    Y_abs_diff = np.abs(Y_arr - Y_hat_arr)\n",
    "    return np.where(Y_abs_diff < delta, 0.5 * Y_abs_diff ** 2 , delta * (Y_abs_diff - 0.5 * delta ** 2)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(X, coeffs):\n",
    "    return X.dot(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, y, coeffs, loss, delta=1.35):\n",
    "    n = len(y)\n",
    "    y_hat = model_predict(X, coeffs)\n",
    "    if loss == 'l2':\n",
    "        grad = (2 / n) * X.T.dot(y_hat - y)\n",
    "    elif loss == 'huber':\n",
    "        s = np.zeros((X.shape[1], 1))\n",
    "        for i in range(n):\n",
    "            diff = y_hat[i] - y[i]\n",
    "            if np.abs(diff) <= delta:\n",
    "                s += ((X[i].T) * diff).reshape(X.shape[1], 1)\n",
    "            else:\n",
    "                sgn = np.sign(diff)\n",
    "                s += (delta * sgn[0] * (X[i].T)).reshape(X.shape[1], 1)\n",
    "        grad = s / n\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, loss, learning_rate, max_iter=100, delta=1.35):\n",
    "    np.random.seed(42)\n",
    "    coeffs = np.random.random(size=X.shape[1])\n",
    "    coeffs = coeffs.reshape(X.shape[1], 1)\n",
    "    for i in range(max_iter):\n",
    "        coeffs = coeffs - learning_rate * gradient(X, y, coeffs, loss)\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(X, y, batch_size):\n",
    "    batches = []\n",
    "    data = np.hstack((X.copy(), y.copy()))\n",
    "    np.random.shuffle(data)\n",
    "    n_batches = data.shape[0] // batch_size\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        batch = data[i * batch_size:(i + 1) * batch_size, :]\n",
    "        X_batch = batch[:, :-1]\n",
    "        y_batch = batch[:, -1].reshape((-1, 1))\n",
    "        batches.append((X_batch, y_batch))\n",
    "\n",
    "    if data.shape[0] % batch_size != 0:\n",
    "        batch = data[i * batch_size:data.shape[0]]\n",
    "        X_batch = batch[:, :-1]\n",
    "        y_batch = batch[:, -1].reshape((-1, 1))\n",
    "        batches.append((X_batch, y_batch))\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_mini_batches(X, y, loss, learning_rate, batch_size=8, alpha=0.01, t0=70, power_t=0.25,\n",
    "                     eta0=0.01, max_iter=100, delta=1.35):\n",
    "    np.random.seed(42)\n",
    "    coeffs = np.random.random(size=X.shape[1])\n",
    "    coeffs = coeffs.reshape(X.shape[1], 1)\n",
    "    n = X.shape[0]\n",
    "    if learning_rate == 'constant':\n",
    "        func = constant\n",
    "    elif learning_rate == 'invscaling':\n",
    "        func = invscaling\n",
    "    elif learning_rate == 'optimal':\n",
    "        func = optimal\n",
    "    if learning_rate != 'adaptive':\n",
    "        for i in range(max_iter):\n",
    "            mini_batches = create_mini_batch(X, y, batch_size)\n",
    "            k = 0\n",
    "            for batch in mini_batches:\n",
    "                X_batch, y_batch = batch\n",
    "                grad = gradient(X_batch, y_batch, coeffs, loss)\n",
    "                \n",
    "                t = i * max_iter + k * batch_size\n",
    "                cur_lr = func(alpha, t0, t, power_t, eta0)\n",
    "                coeffs = coeffs - cur_lr * grad\n",
    "                k += 1\n",
    "    else:\n",
    "        func = adaptive\n",
    "        errors_prev = []\n",
    "        cur_lr = eta0\n",
    "        for i in range(max_iter):\n",
    "            k = 0\n",
    "            errors_prev = errors_prev[-16:]\n",
    "            mini_batches = create_mini_batch(X, y, batch_size)\n",
    "            for batch in mini_batches:\n",
    "                X_batch, y_batch = batch\n",
    "                \n",
    "                grad = gradient(X_batch, y_batch, coeffs, loss)\n",
    "                \n",
    "                t = i * max_iter + k * batch_size\n",
    "                y_hat_sample = model_predict(X_sample, coeffs)\n",
    "                errors_prev.append(loss_l2(y_hat_sample, y_sample))\n",
    "                \n",
    "                if len(errors_prev) > 15:\n",
    "                    lst = errors_prev[-16:].copy()\n",
    "                    if lst.index(max(lst)) == 10:\n",
    "                        cur_lr = func(alpha, t0, t, power_t, eta0, cur_lr)\n",
    "                if cur_lr < 1e-6:\n",
    "                    break\n",
    "                coeffs = coeffs - cur_lr * grad\n",
    "                k += 1\n",
    "                \n",
    "            \n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_mini_batches(X, y, loss, learning_rate, batch_size=8, max_iter=100, delta=1.35):\n",
    "    np.random.seed(0)\n",
    "    coeffs = np.random.random(size=X.shape[1])\n",
    "    coeffs = coeffs.reshape(X.shape[1], 1)\n",
    "    errors = []\n",
    "    for i in range(max_iter):\n",
    "        mini_batches = create_mini_batch(X, y, batch_size)\n",
    "        \n",
    "        for batch in mini_batches:\n",
    "            X_batch, y_batch = batch\n",
    "            coeffs = coeffs - learning_rate * gradient(X_batch, y_batch, coeffs, loss)\n",
    "            errors.append(loss_l2(model_predict(X_batch, coeffs), y_batch))\n",
    "\n",
    "    return coeffs, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_schedule(base_lr, iteration, step=0.005):\n",
    "    cur_lr = base_lr - iteration * step * (2 ** (iteration // 50))\n",
    "    if cur_lr < step * 2:\n",
    "        cur_lr = step\n",
    "    return cur_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal(alpha, t0, t, power_t, eta0):\n",
    "    return 1 / (alpha * (t0 + t))\n",
    "\n",
    "def invscaling(alpha, t0, t, power_t, eta0):\n",
    "    return eta0 / (pow(t + 1, power_t))\n",
    "\n",
    "def constant(alpha, t0, t, power_t, eta0):\n",
    "    return eta0\n",
    "\n",
    "def adaptive(alpha, t0, t, power_t, eta0, cur_lr):\n",
    "    cur_lr = cur_lr / 5\n",
    "    return cur_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, loss, learning_rate, alpha=0.01, t0=70, power_t=0.25,\n",
    "                                eta0=0.01, max_iter=100, delta=1.35):\n",
    "    np.random.seed(42)\n",
    "    coeffs = np.random.random(size=X.shape[1])\n",
    "    coeffs = coeffs.reshape(X.shape[1], 1)\n",
    "    n = X.shape[0]\n",
    "    if learning_rate == 'constant':\n",
    "        func = constant\n",
    "    elif learning_rate == 'invscaling':\n",
    "        func = invscaling\n",
    "    elif learning_rate == 'optimal':\n",
    "        func = optimal\n",
    "    if learning_rate != 'adaptive':\n",
    "        for i in range(max_iter):\n",
    "            indeces = np.arange(n)\n",
    "            np.random.shuffle(indeces)\n",
    "            for j in range(n):\n",
    "                random_index = indeces[j]\n",
    "                X_sample = X[random_index:random_index + 1]\n",
    "                y_sample = y[random_index:random_index + 1]\n",
    "                \n",
    "                grad = gradient(X_sample, y_sample, coeffs, loss)\n",
    "                \n",
    "                t = i * max_iter + j\n",
    "                cur_lr = func(alpha, t0, t, power_t, eta0)\n",
    "                coeffs = coeffs - cur_lr * grad\n",
    "    else:\n",
    "        func = adaptive\n",
    "        errors_prev = []\n",
    "        cur_lr = eta0\n",
    "        for i in range(max_iter):\n",
    "            errors_prev = errors_prev[-16:]\n",
    "            indeces = np.arange(n)\n",
    "            np.random.shuffle(indeces)\n",
    "            for j in range(n):\n",
    "                random_index = indeces[j]\n",
    "                X_sample = X[random_index:random_index + 1]\n",
    "                y_sample = y[random_index:random_index + 1]\n",
    "                \n",
    "                grad = gradient(X_sample, y_sample, coeffs, loss)\n",
    "                \n",
    "                t = i * max_iter + j\n",
    "                y_hat_sample = model_predict(X_sample, coeffs)\n",
    "                errors_prev.append(loss_l2(y_hat_sample, y_sample))\n",
    "                \n",
    "                if len(errors_prev) > 15:\n",
    "                    lst = errors_prev[-16:].copy()\n",
    "                    if lst.index(max(lst)) == 10:\n",
    "                        cur_lr = func(alpha, t0, t, power_t, eta0, cur_lr)\n",
    "                if cur_lr < 1e-6:\n",
    "                    break\n",
    "                coeffs = coeffs - cur_lr * grad\n",
    "                \n",
    "            \n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('boston.csv')\n",
    "train_sample, test_sample = split_sample(data, 0.9, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors_ind = ['age', 'rm', 'lstat']\n",
    "explained_var_ind = 'medv'\n",
    "    \n",
    "X_train, Y_train = x_y_splitting(train_sample, regressors_ind, explained_var_ind)\n",
    "X_test, Y_test = x_y_splitting(test_sample, regressors_ind, explained_var_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, mu, sigma = feature_normalize(X_train)\n",
    "X_train = insert_ones(X_train)\n",
    "    \n",
    "covXX = eigens_and_conidtion(X_train, printing='no')\n",
    "beta_OLS = model_coeffs(X_train, Y_train, covXX)\n",
    "Y_hat_train = model_predict(X_train, beta_OLS)\n",
    "    \n",
    "X_test, _, _ = feature_normalize(X_test, mu, sigma)\n",
    "X_test = insert_ones(X_test)\n",
    "Y_hat_test = model_predict(X_test, beta_OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = gradient_descent(np.array(X_train), np.array(Y_train), loss='l2', learning_rate=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.25243441e+01],\n",
       "       [-1.50909207e-02],\n",
       "       [ 3.86447691e+00],\n",
       "       [-4.34354549e+00]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_test_2 = model_predict(X_test, coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>21.465596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>19.858753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>19.110032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>25.742328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>14.992440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>7.019512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>21.829132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>4.827528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>26.109024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>5.635206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>26.527612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>32.531807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>23.810379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>18.579626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>21.123351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>23.998715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>29.401074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>27.655686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>21.726652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>18.647288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>9.409071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>19.920528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>25.685321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>26.924737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16.416295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>23.212578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>21.661565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>10.854406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>22.024562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>20.418734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>29.268920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>29.947072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>26.052380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>19.009909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>30.734923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>22.254522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>26.851049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>24.176947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>29.224646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>23.758736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>30.609216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>10.799612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.239734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>21.530988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>36.990633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>28.875228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>19.924329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>33.296187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>22.487441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>17.341594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>17.381056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "185  21.465596\n",
       "476  19.858753\n",
       "449  19.110032\n",
       "288  25.742328\n",
       "423  14.992440\n",
       "398   7.019512\n",
       "462  21.829132\n",
       "147   4.827528\n",
       "285  26.109024\n",
       "490   5.635206\n",
       "177  26.527612\n",
       "99   32.531807\n",
       "338  23.810379\n",
       "448  18.579626\n",
       "431  21.123351\n",
       "335  23.998715\n",
       "197  29.401074\n",
       "243  27.655686\n",
       "464  21.726652\n",
       "115  18.647288\n",
       "404   9.409071\n",
       "265  19.920528\n",
       "72   25.685321\n",
       "333  26.924737\n",
       "25   16.416295\n",
       "165  23.212578\n",
       "337  21.661565\n",
       "489  10.854406\n",
       "174  22.024562\n",
       "492  20.418734\n",
       "39   29.268920\n",
       "193  29.947072\n",
       "314  26.052380\n",
       "396  19.009909\n",
       "88   30.734923\n",
       "472  22.254522\n",
       "70   26.851049\n",
       "87   24.176947\n",
       "292  29.224646\n",
       "242  23.758736\n",
       "277  30.609216\n",
       "211  10.799612\n",
       "9    18.239734\n",
       "359  21.530988\n",
       "195  36.990633\n",
       "251  28.875228\n",
       "323  19.924329\n",
       "192  33.296187\n",
       "117  22.487441\n",
       "47   17.341594\n",
       "172  17.381056"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08930139544051689\n"
     ]
    }
   ],
   "source": [
    "print(loss_l2(Y_hat_test, Y_hat_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs_new, errors = gradient_descent_mini_batches(np.array(X_train), np.array(Y_train), loss='l2',\n",
    "                                                   batch_size=28, max_iter=100, learning_rate=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23.15916997],\n",
       "       [ 0.17706599],\n",
       "       [ 2.89784086],\n",
       "       [-5.32556055]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_test_3 = model_predict(X_test, coeffs_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>22.217026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>19.570518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>18.857490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>26.882202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>14.522911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>6.520972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>22.341018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>5.156663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>26.881489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>5.734186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>28.039678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>32.497600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>25.112772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>18.805753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>20.229678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>25.380580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>29.271231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>28.763169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>22.369487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>19.475182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>9.148243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>21.803481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>27.189652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>28.276857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17.567176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>24.661957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>23.055441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>11.311132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>23.656672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>21.472977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>30.320413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>30.542115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>26.907179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>18.749443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>31.511439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>22.498403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>27.706581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>25.539531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>30.187450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>24.390836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>31.411122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>11.201713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.764210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>22.490015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>36.572217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>30.150573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>21.508590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>33.792526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>23.905502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>17.593444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>18.838998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "185  22.217026\n",
       "476  19.570518\n",
       "449  18.857490\n",
       "288  26.882202\n",
       "423  14.522911\n",
       "398   6.520972\n",
       "462  22.341018\n",
       "147   5.156663\n",
       "285  26.881489\n",
       "490   5.734186\n",
       "177  28.039678\n",
       "99   32.497600\n",
       "338  25.112772\n",
       "448  18.805753\n",
       "431  20.229678\n",
       "335  25.380580\n",
       "197  29.271231\n",
       "243  28.763169\n",
       "464  22.369487\n",
       "115  19.475182\n",
       "404   9.148243\n",
       "265  21.803481\n",
       "72   27.189652\n",
       "333  28.276857\n",
       "25   17.567176\n",
       "165  24.661957\n",
       "337  23.055441\n",
       "489  11.311132\n",
       "174  23.656672\n",
       "492  21.472977\n",
       "39   30.320413\n",
       "193  30.542115\n",
       "314  26.907179\n",
       "396  18.749443\n",
       "88   31.511439\n",
       "472  22.498403\n",
       "70   27.706581\n",
       "87   25.539531\n",
       "292  30.187450\n",
       "242  24.390836\n",
       "277  31.411122\n",
       "211  11.201713\n",
       "9    18.764210\n",
       "359  22.490015\n",
       "195  36.572217\n",
       "251  30.150573\n",
       "323  21.508590\n",
       "192  33.792526\n",
       "117  23.905502\n",
       "47   17.593444\n",
       "172  18.838998"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat_test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9253248629624105\n"
     ]
    }
   ],
   "source": [
    "print(loss_l2(Y_hat_test_2, Y_hat_test_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs_sgd = stochastic_gradient_descent(np.array(X_train), np.array(Y_train), loss='l2',\n",
    "                                         max_iter=100, learning_rate='invscaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_test_sgd = model_predict(X_test, coeffs_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>21.539053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>19.712122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>19.014472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>25.802995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>14.651741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>6.733775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>21.935200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>4.827478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>25.895983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>5.567435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>27.001839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>32.316774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>23.846602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>18.681807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>20.742642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>24.044114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>28.884421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>27.376137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>21.726410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>18.904465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>9.109904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>20.395877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>25.553597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>27.015525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16.765717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>23.810339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>21.919801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>10.982513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>22.467386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>20.742346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>29.107042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>29.493540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>26.375954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>18.889323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>31.057023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>22.180382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>26.449156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>24.418314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>29.040107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>23.657961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>30.407887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>10.816521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.346621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>21.804636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>36.377442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>28.685771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>20.380151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>32.979249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>22.971583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>17.324018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>17.891590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "185  21.539053\n",
       "476  19.712122\n",
       "449  19.014472\n",
       "288  25.802995\n",
       "423  14.651741\n",
       "398   6.733775\n",
       "462  21.935200\n",
       "147   4.827478\n",
       "285  25.895983\n",
       "490   5.567435\n",
       "177  27.001839\n",
       "99   32.316774\n",
       "338  23.846602\n",
       "448  18.681807\n",
       "431  20.742642\n",
       "335  24.044114\n",
       "197  28.884421\n",
       "243  27.376137\n",
       "464  21.726410\n",
       "115  18.904465\n",
       "404   9.109904\n",
       "265  20.395877\n",
       "72   25.553597\n",
       "333  27.015525\n",
       "25   16.765717\n",
       "165  23.810339\n",
       "337  21.919801\n",
       "489  10.982513\n",
       "174  22.467386\n",
       "492  20.742346\n",
       "39   29.107042\n",
       "193  29.493540\n",
       "314  26.375954\n",
       "396  18.889323\n",
       "88   31.057023\n",
       "472  22.180382\n",
       "70   26.449156\n",
       "87   24.418314\n",
       "292  29.040107\n",
       "242  23.657961\n",
       "277  30.407887\n",
       "211  10.816521\n",
       "9    18.346621\n",
       "359  21.804636\n",
       "195  36.377442\n",
       "251  28.685771\n",
       "323  20.380151\n",
       "192  32.979249\n",
       "117  22.971583\n",
       "47   17.324018\n",
       "172  17.891590"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat_test_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02063554971486393\n"
     ]
    }
   ],
   "source": [
    "print(loss_l2(Y_hat_test, Y_hat_test_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.19706101],\n",
       "       [-0.1336059 ],\n",
       "       [ 3.93820801],\n",
       "       [-4.17099556]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_mini_batch_sgd = sgd_mini_batches(np.array(X_train), np.array(Y_train), loss='l2', learning_rate='invscaling', batch_size=32)\n",
    "coeffs_mini_batch_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>21.137281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>19.593473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>18.833206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>25.394426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>14.835908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>6.910047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>21.477825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>4.656362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>25.848741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>5.475103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>26.029960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>32.191256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>23.493441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>18.248595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>20.915520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>23.679260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>29.197357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>27.417710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>21.420224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>18.276850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>9.291676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>19.491134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>25.421607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>26.562165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16.040818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>22.695171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>21.282885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>10.587479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>21.581239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>20.015409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>28.971209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>29.738177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>25.594241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>18.743063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>30.234560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>21.958486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>26.657766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>23.781949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>28.932970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>23.472139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>30.306779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>10.573057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.919395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>21.133767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>36.748574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>28.598383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>19.492673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>33.004175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>22.017824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>17.066885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>16.946750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "185  21.137281\n",
       "476  19.593473\n",
       "449  18.833206\n",
       "288  25.394426\n",
       "423  14.835908\n",
       "398   6.910047\n",
       "462  21.477825\n",
       "147   4.656362\n",
       "285  25.848741\n",
       "490   5.475103\n",
       "177  26.029960\n",
       "99   32.191256\n",
       "338  23.493441\n",
       "448  18.248595\n",
       "431  20.915520\n",
       "335  23.679260\n",
       "197  29.197357\n",
       "243  27.417710\n",
       "464  21.420224\n",
       "115  18.276850\n",
       "404   9.291676\n",
       "265  19.491134\n",
       "72   25.421607\n",
       "333  26.562165\n",
       "25   16.040818\n",
       "165  22.695171\n",
       "337  21.282885\n",
       "489  10.587479\n",
       "174  21.581239\n",
       "492  20.015409\n",
       "39   28.971209\n",
       "193  29.738177\n",
       "314  25.594241\n",
       "396  18.743063\n",
       "88   30.234560\n",
       "472  21.958486\n",
       "70   26.657766\n",
       "87   23.781949\n",
       "292  28.932970\n",
       "242  23.472139\n",
       "277  30.306779\n",
       "211  10.573057\n",
       "9    17.919395\n",
       "359  21.133767\n",
       "195  36.748574\n",
       "251  28.598383\n",
       "323  19.492673\n",
       "192  33.004175\n",
       "117  22.017824\n",
       "47   17.066885\n",
       "172  16.946750"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat_test_mini_batch_sgd = model_predict(X_test, coeffs_mini_batch_sgd)\n",
    "Y_hat_test_mini_batch_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3166215038069921\n"
     ]
    }
   ],
   "source": [
    "print(loss_l2(Y_hat_test, Y_hat_test_mini_batch_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "p = 6\n",
    "def binomial_coeff(k, n):\n",
    "    return math.factorial(n) // (math.factorial(k) * math.factorial(n - k))\n",
    "\n",
    "def create_monomials(order, X, x1, x2):\n",
    "    X_copy = np.array(X.loc[:, (x1, x2)].copy())\n",
    "    amount = (order + 1) * (order + 2) // 2\n",
    "    indeces = X.index\n",
    "    names = []\n",
    "    data = np.zeros((X.shape[0], amount))\n",
    "    for degree in range(order + 1):\n",
    "        for x1_degree in range(degree + 1):\n",
    "            data[:, degree * (degree + 1) // 2 + x1_degree] = (X_copy[:, 0] ** x1_degree) * (X_copy[:, 1] ** (degree - x1_degree))\n",
    "            first_name = str(x1_degree)\n",
    "            second_name = str(degree - x1_degree)\n",
    "            names.append(first_name + ' , ' + second_name)\n",
    "    data = pd.DataFrame(data=data, index=indeces, columns=names)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1= 'age'\n",
    "x2 ='rm'\n",
    "X_train.loc[:, (x1, x2)]\n",
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>rm</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>17.2</td>\n",
       "      <td>6.333</td>\n",
       "      <td>7.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>100.0</td>\n",
       "      <td>6.216</td>\n",
       "      <td>9.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>92.4</td>\n",
       "      <td>6.373</td>\n",
       "      <td>10.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>96.0</td>\n",
       "      <td>5.349</td>\n",
       "      <td>19.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>53.7</td>\n",
       "      <td>6.232</td>\n",
       "      <td>12.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>76.5</td>\n",
       "      <td>5.593</td>\n",
       "      <td>12.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>15.7</td>\n",
       "      <td>7.610</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>100.0</td>\n",
       "      <td>6.072</td>\n",
       "      <td>13.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>82.0</td>\n",
       "      <td>5.950</td>\n",
       "      <td>27.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>96.0</td>\n",
       "      <td>5.693</td>\n",
       "      <td>17.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     rm  lstat\n",
       "329   17.2  6.333   7.34\n",
       "371  100.0  6.216   9.53\n",
       "219   92.4  6.373  10.50\n",
       "403   96.0  5.349  19.77\n",
       "78    53.7  6.232  12.34\n",
       "..     ...    ...    ...\n",
       "244   76.5  5.593  12.50\n",
       "202   15.7  7.610   3.11\n",
       "31   100.0  6.072  13.04\n",
       "32    82.0  5.950  27.71\n",
       "127   96.0  5.693  17.19\n",
       "\n",
       "[455 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('age', 'rm')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0 , 0</th>\n",
       "      <th>0 , 1</th>\n",
       "      <th>1 , 0</th>\n",
       "      <th>0 , 2</th>\n",
       "      <th>1 , 1</th>\n",
       "      <th>2 , 0</th>\n",
       "      <th>0 , 3</th>\n",
       "      <th>1 , 2</th>\n",
       "      <th>2 , 1</th>\n",
       "      <th>3 , 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.333</td>\n",
       "      <td>17.2</td>\n",
       "      <td>40.106889</td>\n",
       "      <td>108.9276</td>\n",
       "      <td>295.84</td>\n",
       "      <td>253.996928</td>\n",
       "      <td>689.838491</td>\n",
       "      <td>1873.55472</td>\n",
       "      <td>5088.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.216</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.638656</td>\n",
       "      <td>621.6000</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>240.177886</td>\n",
       "      <td>3863.865600</td>\n",
       "      <td>62160.00000</td>\n",
       "      <td>1000000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.373</td>\n",
       "      <td>92.4</td>\n",
       "      <td>40.615129</td>\n",
       "      <td>588.8652</td>\n",
       "      <td>8537.76</td>\n",
       "      <td>258.840217</td>\n",
       "      <td>3752.837920</td>\n",
       "      <td>54411.14448</td>\n",
       "      <td>788889.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.349</td>\n",
       "      <td>96.0</td>\n",
       "      <td>28.611801</td>\n",
       "      <td>513.5040</td>\n",
       "      <td>9216.00</td>\n",
       "      <td>153.044524</td>\n",
       "      <td>2746.732896</td>\n",
       "      <td>49296.38400</td>\n",
       "      <td>884736.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.232</td>\n",
       "      <td>53.7</td>\n",
       "      <td>38.837824</td>\n",
       "      <td>334.6584</td>\n",
       "      <td>2883.69</td>\n",
       "      <td>242.037319</td>\n",
       "      <td>2085.591149</td>\n",
       "      <td>17971.15608</td>\n",
       "      <td>154854.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.593</td>\n",
       "      <td>76.5</td>\n",
       "      <td>31.281649</td>\n",
       "      <td>427.8645</td>\n",
       "      <td>5852.25</td>\n",
       "      <td>174.958263</td>\n",
       "      <td>2393.046149</td>\n",
       "      <td>32731.63425</td>\n",
       "      <td>447697.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.610</td>\n",
       "      <td>15.7</td>\n",
       "      <td>57.912100</td>\n",
       "      <td>119.4770</td>\n",
       "      <td>246.49</td>\n",
       "      <td>440.711081</td>\n",
       "      <td>909.219970</td>\n",
       "      <td>1875.78890</td>\n",
       "      <td>3869.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.072</td>\n",
       "      <td>100.0</td>\n",
       "      <td>36.869184</td>\n",
       "      <td>607.2000</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>223.869685</td>\n",
       "      <td>3686.918400</td>\n",
       "      <td>60720.00000</td>\n",
       "      <td>1000000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.950</td>\n",
       "      <td>82.0</td>\n",
       "      <td>35.402500</td>\n",
       "      <td>487.9000</td>\n",
       "      <td>6724.00</td>\n",
       "      <td>210.644875</td>\n",
       "      <td>2903.005000</td>\n",
       "      <td>40007.80000</td>\n",
       "      <td>551368.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.693</td>\n",
       "      <td>96.0</td>\n",
       "      <td>32.410249</td>\n",
       "      <td>546.5280</td>\n",
       "      <td>9216.00</td>\n",
       "      <td>184.511548</td>\n",
       "      <td>3111.383904</td>\n",
       "      <td>52466.68800</td>\n",
       "      <td>884736.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0 , 0  0 , 1  1 , 0      0 , 2     1 , 1     2 , 0       0 , 3  \\\n",
       "329    1.0  6.333   17.2  40.106889  108.9276    295.84  253.996928   \n",
       "371    1.0  6.216  100.0  38.638656  621.6000  10000.00  240.177886   \n",
       "219    1.0  6.373   92.4  40.615129  588.8652   8537.76  258.840217   \n",
       "403    1.0  5.349   96.0  28.611801  513.5040   9216.00  153.044524   \n",
       "78     1.0  6.232   53.7  38.837824  334.6584   2883.69  242.037319   \n",
       "..     ...    ...    ...        ...       ...       ...         ...   \n",
       "244    1.0  5.593   76.5  31.281649  427.8645   5852.25  174.958263   \n",
       "202    1.0  7.610   15.7  57.912100  119.4770    246.49  440.711081   \n",
       "31     1.0  6.072  100.0  36.869184  607.2000  10000.00  223.869685   \n",
       "32     1.0  5.950   82.0  35.402500  487.9000   6724.00  210.644875   \n",
       "127    1.0  5.693   96.0  32.410249  546.5280   9216.00  184.511548   \n",
       "\n",
       "           1 , 2        2 , 1        3 , 0  \n",
       "329   689.838491   1873.55472     5088.448  \n",
       "371  3863.865600  62160.00000  1000000.000  \n",
       "219  3752.837920  54411.14448   788889.024  \n",
       "403  2746.732896  49296.38400   884736.000  \n",
       "78   2085.591149  17971.15608   154854.153  \n",
       "..           ...          ...          ...  \n",
       "244  2393.046149  32731.63425   447697.125  \n",
       "202   909.219970   1875.78890     3869.893  \n",
       "31   3686.918400  60720.00000  1000000.000  \n",
       "32   2903.005000  40007.80000   551368.000  \n",
       "127  3111.383904  52466.68800   884736.000  \n",
       "\n",
       "[455 rows x 10 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = create_monomials(3, X_train, x1, x2)\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0, 0</th>\n",
       "      <th>0 , 1</th>\n",
       "      <th>1 , 0</th>\n",
       "      <th>0 , 2</th>\n",
       "      <th>1 , 1</th>\n",
       "      <th>2 , 0</th>\n",
       "      <th>0 , 3</th>\n",
       "      <th>1 , 2</th>\n",
       "      <th>2 , 1</th>\n",
       "      <th>3 , 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.333</td>\n",
       "      <td>17.2</td>\n",
       "      <td>40.106889</td>\n",
       "      <td>108.9276</td>\n",
       "      <td>295.84</td>\n",
       "      <td>253.996928</td>\n",
       "      <td>689.838491</td>\n",
       "      <td>1873.55472</td>\n",
       "      <td>5088.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.216</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.638656</td>\n",
       "      <td>621.6000</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>240.177886</td>\n",
       "      <td>3863.865600</td>\n",
       "      <td>62160.00000</td>\n",
       "      <td>1000000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.373</td>\n",
       "      <td>92.4</td>\n",
       "      <td>40.615129</td>\n",
       "      <td>588.8652</td>\n",
       "      <td>8537.76</td>\n",
       "      <td>258.840217</td>\n",
       "      <td>3752.837920</td>\n",
       "      <td>54411.14448</td>\n",
       "      <td>788889.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.349</td>\n",
       "      <td>96.0</td>\n",
       "      <td>28.611801</td>\n",
       "      <td>513.5040</td>\n",
       "      <td>9216.00</td>\n",
       "      <td>153.044524</td>\n",
       "      <td>2746.732896</td>\n",
       "      <td>49296.38400</td>\n",
       "      <td>884736.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.232</td>\n",
       "      <td>53.7</td>\n",
       "      <td>38.837824</td>\n",
       "      <td>334.6584</td>\n",
       "      <td>2883.69</td>\n",
       "      <td>242.037319</td>\n",
       "      <td>2085.591149</td>\n",
       "      <td>17971.15608</td>\n",
       "      <td>154854.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.593</td>\n",
       "      <td>76.5</td>\n",
       "      <td>31.281649</td>\n",
       "      <td>427.8645</td>\n",
       "      <td>5852.25</td>\n",
       "      <td>174.958263</td>\n",
       "      <td>2393.046149</td>\n",
       "      <td>32731.63425</td>\n",
       "      <td>447697.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.610</td>\n",
       "      <td>15.7</td>\n",
       "      <td>57.912100</td>\n",
       "      <td>119.4770</td>\n",
       "      <td>246.49</td>\n",
       "      <td>440.711081</td>\n",
       "      <td>909.219970</td>\n",
       "      <td>1875.78890</td>\n",
       "      <td>3869.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.072</td>\n",
       "      <td>100.0</td>\n",
       "      <td>36.869184</td>\n",
       "      <td>607.2000</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>223.869685</td>\n",
       "      <td>3686.918400</td>\n",
       "      <td>60720.00000</td>\n",
       "      <td>1000000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.950</td>\n",
       "      <td>82.0</td>\n",
       "      <td>35.402500</td>\n",
       "      <td>487.9000</td>\n",
       "      <td>6724.00</td>\n",
       "      <td>210.644875</td>\n",
       "      <td>2903.005000</td>\n",
       "      <td>40007.80000</td>\n",
       "      <td>551368.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.693</td>\n",
       "      <td>96.0</td>\n",
       "      <td>32.410249</td>\n",
       "      <td>546.5280</td>\n",
       "      <td>9216.00</td>\n",
       "      <td>184.511548</td>\n",
       "      <td>3111.383904</td>\n",
       "      <td>52466.68800</td>\n",
       "      <td>884736.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0, 0  0 , 1  1 , 0      0 , 2     1 , 1     2 , 0       0 , 3  \\\n",
       "329   1.0  6.333   17.2  40.106889  108.9276    295.84  253.996928   \n",
       "371   1.0  6.216  100.0  38.638656  621.6000  10000.00  240.177886   \n",
       "219   1.0  6.373   92.4  40.615129  588.8652   8537.76  258.840217   \n",
       "403   1.0  5.349   96.0  28.611801  513.5040   9216.00  153.044524   \n",
       "78    1.0  6.232   53.7  38.837824  334.6584   2883.69  242.037319   \n",
       "..    ...    ...    ...        ...       ...       ...         ...   \n",
       "244   1.0  5.593   76.5  31.281649  427.8645   5852.25  174.958263   \n",
       "202   1.0  7.610   15.7  57.912100  119.4770    246.49  440.711081   \n",
       "31    1.0  6.072  100.0  36.869184  607.2000  10000.00  223.869685   \n",
       "32    1.0  5.950   82.0  35.402500  487.9000   6724.00  210.644875   \n",
       "127   1.0  5.693   96.0  32.410249  546.5280   9216.00  184.511548   \n",
       "\n",
       "           1 , 2        2 , 1        3 , 0  \n",
       "329   689.838491   1873.55472     5088.448  \n",
       "371  3863.865600  62160.00000  1000000.000  \n",
       "219  3752.837920  54411.14448   788889.024  \n",
       "403  2746.732896  49296.38400   884736.000  \n",
       "78   2085.591149  17971.15608   154854.153  \n",
       "..           ...          ...          ...  \n",
       "244  2393.046149  32731.63425   447697.125  \n",
       "202   909.219970   1875.78890     3869.893  \n",
       "31   3686.918400  60720.00000  1000000.000  \n",
       "32   2903.005000  40007.80000   551368.000  \n",
       "127  3111.383904  52466.68800   884736.000  \n",
       "\n",
       "[455 rows x 10 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dat.iloc[:, 1:].copy()\n",
    "d = insert_ones(d, name='0, 0')\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_polynomial_model(order, X_train, Y_train, x1, x2, change=True, betas=None, mu=None, sigma=None):\n",
    "    V_train = create_monomials(order, X_train, x1, x2)\n",
    "    V_train, mu, sigma = feature_normalize(V_train.iloc[:, 1:], mu, sigma)\n",
    "    V_train = insert_ones(V_train, name='0, 0')\n",
    "    \n",
    "    covXX = eigens_and_conidtion(V_train, printing='no')\n",
    "    if change == True:\n",
    "        beta_OLS = model_coeffs(V_train, Y_train, covXX)\n",
    "        Y_hat_train = model_predict(V_train, beta_OLS)\n",
    "    \n",
    "        return Y_hat_train, beta_OLS, mu, sigma\n",
    "    else:\n",
    "        Y_hat_train = model_predict(V_train, betas)\n",
    "        return Y_hat_train, betas, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('boston.csv')\n",
    "train_sample, test_sample = split_sample(data, 0.8, True)\n",
    "\n",
    "regressors_ind = ['lstat', 'nox']\n",
    "explained_var_ind = 'medv'\n",
    "    \n",
    "X_train, Y_train = x_y_splitting(train_sample, regressors_ind, explained_var_ind)\n",
    "X_test, Y_test = x_y_splitting(test_sample, regressors_ind, explained_var_ind)\n",
    "\n",
    "x1= 'lstat'\n",
    "x2 ='nox'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 7\n",
    "n_train = X_train.shape[0]\n",
    "\n",
    "#k = (p + 2)* (p + 1) // 2\n",
    "MSE_train_fold = np.zeros((p, n_train))\n",
    "CV_MSE_fold = np.zeros((p, n_train))\n",
    "MSE_train = np.zeros((p, 1))\n",
    "MSE_test = np.zeros((p, 1))\n",
    "MSE_gen = np.zeros((p, 1))\n",
    "CV_MSE = np.zeros((p, 1))\n",
    "\n",
    "indeces = np.array(X_train.index.copy())\n",
    "for order in range(p):\n",
    "    for iteration in range(n_train):\n",
    "        \n",
    "        X_train_copy = X_train.copy()\n",
    "        Y_train_copy = Y_train.copy()\n",
    "            \n",
    "        X_fold = X_train_copy.iloc[iteration:iteration + 1]\n",
    "        Y_fold = Y_train_copy.iloc[iteration:iteration + 1]\n",
    "            \n",
    "        X_train_fold = X_train_copy.drop(indeces[iteration])\n",
    "        Y_train_fold = Y_train_copy.drop(indeces[iteration])\n",
    "        #X_fold = X_train[iteration: iteration + 1]\n",
    "        #Y_fold = Y_train[iteration: iteration + 1]\n",
    "        #X_train_fold = X_train[np.r_[0:iteration, iteration + 1:n_train]]\n",
    "        #Y_train_fold = Y_train[np.r_[0:iteration, iteration + 1:n_train]]\n",
    "        \n",
    "        Y_hat_train_fold, beta_train_fold, mu_fold, sigma_fold = create_polynomial_model(order, X_train_fold, Y_train_fold, x1, x2)\n",
    "        MSE_train_fold[order, iteration] = loss_l2(Y_hat_train_fold, Y_train_fold)\n",
    "        Y_hat_fold, _, _, _ = create_polynomial_model(order, X_fold, Y_fold, x1, x2, False, beta_train_fold, mu_fold, sigma_fold)\n",
    "        CV_MSE_fold[order, iteration] = loss_l2(Y_hat_fold, Y_fold)\n",
    "        \n",
    "    CV_MSE[order] = CV_MSE_fold[order, :].mean()\n",
    "    MSE_train[order] = MSE_train_fold[order, :].mean()\n",
    "    \n",
    "    Y_hat_train, beta_train, mu, sigma = create_polynomial_model(order, X_train, Y_train, x1, x2)\n",
    "    Y_hat_test, _, _, _ = create_polynomial_model(order, X_test, Y_test, x1, x2, False, beta_train, mu, sigma)\n",
    "    MSE_test[order] = loss_l2(Y_hat_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_opt = 4\n",
    "dots = [MSE_train[p_opt], CV_MSE[p_opt], MSE_test[p_opt]]\n",
    "\n",
    "\n",
    "plt.plot(MSE_train, color='magenta')\n",
    "plt.plot(CV_MSE, color='blue')\n",
    "plt.plot(MSE_test, color='red')\n",
    "plt.scatter([p_opt for _ in range(3)], dots, color='black')\n",
    "plt.legend(('Training error', 'Cross-validation k-fold error', 'Test error', 'p_opt errors'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
